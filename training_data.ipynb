{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665a72f7-5513-4986-b631-90602b228998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56300,)\n",
      "(65300,)\n",
      "(66700,)\n",
      "(68100,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def unison_shuffled_copies(a, b, c):\n",
    "    assert len(a) == len(b) == len(c)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p], p\n",
    "\n",
    "nstudies_arr = np.empty((50000,))\n",
    "nsub_total = np.empty((50000,))\n",
    "nsub_mean = np.empty((50000,))\n",
    "nsub_median = np.empty((50000,))\n",
    "nsub_std = np.empty((50000,))\n",
    "nsub_max = np.empty((50000,))\n",
    "nsub_min = np.empty((50000,))\n",
    "nsub_skew = np.empty((50000,))\n",
    "nsub_krt = np.empty((50000,))\n",
    "\n",
    "nfoci_total = np.empty((50000,))\n",
    "nfoci_mean = np.empty((50000,))\n",
    "nfoci_median = np.empty((50000,))\n",
    "nfoci_std = np.empty((50000,))\n",
    "nfoci_max = np.empty((50000,))\n",
    "nfoci_min = np.empty((50000,))\n",
    "nfoci_skew = np.empty((50000,))\n",
    "nfoci_krt = np.empty((50000,))\n",
    "\n",
    "ratio_mean = np.empty((50000,))\n",
    "ratio_std = np.empty((50000,))\n",
    "ratio_max = np.empty((50000,))\n",
    "ratio_min = np.empty((50000,))\n",
    "nstudies_foci_ratio = np.empty((50000,))\n",
    "\n",
    "hi_foci = np.empty((50000,))\n",
    "mi_foci = np.empty((50000,))\n",
    "li_foci = np.empty((50000,))\n",
    "vi_foci = np.empty((50000,))\n",
    "\n",
    "with h5py.File('input/simulation_data_cutoff_10to20.hdf5','r') as sim_data1:\n",
    "    with h5py.File('input/simulation_data_cutoff_130722.hdf5','r') as sim_data2:\n",
    "        with h5py.File('input/simulation_data_cutoff_100to150.hdf5','r') as sim_data3:\n",
    "            counter = 0\n",
    "            for nstudies in range(10,150):\n",
    "                if nstudies < 20:\n",
    "                    sim_data = sim_data1\n",
    "                    reps = 500\n",
    "                elif (nstudies >= 20) and (nstudies < 100):\n",
    "                    sim_data = sim_data2\n",
    "                    reps = 500\n",
    "                else:\n",
    "                    sim_data = sim_data3\n",
    "                    reps = 100\n",
    "                for rep in range(reps):\n",
    "                    nstudies_arr[counter] = nstudies\n",
    "                    nfoci_arr_counter = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "                    nfoci_total[counter] = np.sum(nfoci_arr_counter)\n",
    "                    nfoci_mean[counter] = np.mean(nfoci_arr_counter)\n",
    "                    nfoci_median[counter] = np.median(nfoci_arr_counter)\n",
    "                    nfoci_std[counter] = np.std(nfoci_arr_counter)\n",
    "                    nfoci_max[counter] = np.max(nfoci_arr_counter)\n",
    "                    nfoci_min[counter] = np.min(nfoci_arr_counter)\n",
    "                    nfoci_skew[counter] = skew(nfoci_arr_counter)\n",
    "                    nfoci_krt[counter] = kurtosis(nfoci_arr_counter)\n",
    "    \n",
    "                    nsub_arr_counter = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "                    nsub_total[counter] = np.sum(nsub_arr_counter)\n",
    "                    nsub_mean[counter] = np.mean(nsub_arr_counter)\n",
    "                    nsub_median[counter] = np.median(nsub_arr_counter)\n",
    "                    nsub_std[counter] = np.std(nsub_arr_counter)\n",
    "                    nsub_max[counter] = np.max(nsub_arr_counter)\n",
    "                    nsub_min[counter] = np.min(nsub_arr_counter)\n",
    "                    nsub_skew[counter] = skew(nsub_arr_counter)\n",
    "                    nsub_krt[counter] = kurtosis(nsub_arr_counter)\n",
    "\n",
    "                    ratio_mean[counter] = np.mean(nfoci_arr_counter / nsub_arr_counter)\n",
    "                    ratio_std[counter] = np.std(nfoci_arr_counter / nsub_arr_counter)\n",
    "                    ratio_max[counter] = np.max(nfoci_arr_counter / nsub_arr_counter)\n",
    "                    ratio_min[counter] = np.min(nfoci_arr_counter / nsub_arr_counter)\n",
    "                    \n",
    "                    nstudies_foci_ratio[counter] = np.sum(nfoci_arr_counter) / nstudies\n",
    "                    \n",
    "                    hi_foci_counter = 0\n",
    "                    mi_foci_counter = 0\n",
    "                    li_foci_counter = 0\n",
    "                    vi_foci_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "                    for i in range(nstudies):\n",
    "                        if nsub_arr_counter[i] > 20:\n",
    "                            hi_foci_counter += nfoci_arr_counter[i]\n",
    "                        if (nsub_arr_counter[i] < 20) and (nsub_arr_counter[i] > 15):\n",
    "                            mi_foci_counter += nfoci_arr_counter[i]\n",
    "                        if (nsub_arr_counter[i] < 15) and (nsub_arr_counter[i] > 10):\n",
    "                            li_foci_counter += nfoci_arr_counter[i]\n",
    "                        if nsub_arr_counter[i] < 10:\n",
    "                            vi_foci_counter += nfoci_arr_counter[i]\n",
    "\n",
    "                    hi_foci[counter] = hi_foci_counter\n",
    "                    mi_foci[counter] = mi_foci_counter\n",
    "                    li_foci[counter] = li_foci_counter\n",
    "                    vi_foci[counter] = vi_foci_counter\n",
    "                    \n",
    "\n",
    "                    counter += 1\n",
    "\n",
    "with h5py.File('input/simulation_data_cutoff_extremes.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,150):\n",
    "        for foci_cat in ['low','medium','high']:\n",
    "            for subj_cat in ['low','medium','high']:\n",
    "                for rep in range(5):\n",
    "                    nstudies_arr = np.append(nstudies_arr, nstudies)\n",
    "                    \n",
    "                    nfoci_arr_counter = sim_data[f'{nstudies}/{foci_cat}/{subj_cat}/{rep}/nfoci'][:]\n",
    "                    nfoci_total = np.append(nfoci_total, np.sum(nfoci_arr_counter))\n",
    "                    nfoci_mean = np.append(nfoci_mean, np.mean(nfoci_arr_counter))\n",
    "                    nfoci_median = np.append(nfoci_median, np.median(nfoci_arr_counter))\n",
    "                    nfoci_std = np.append(nfoci_std, np.std(nfoci_arr_counter))\n",
    "                    nfoci_max = np.append(nfoci_max, np.max(nfoci_arr_counter))\n",
    "                    nfoci_min = np.append(nfoci_min, np.min(nfoci_arr_counter))\n",
    "                    nfoci_skew = np.append(nfoci_skew, skew(nfoci_arr_counter))\n",
    "                    nfoci_krt = np.append(nfoci_krt, kurtosis(nfoci_arr_counter))\n",
    "\n",
    "                    nsub_arr_counter = sim_data[f'{nstudies}/{foci_cat}/{subj_cat}/{rep}/nsub'][:]\n",
    "                    nsub_total = np.append(nsub_total, np.sum(nsub_arr_counter))\n",
    "                    nsub_mean = np.append(nsub_mean, np.mean(nsub_arr_counter))\n",
    "                    nsub_median = np.append(nsub_median, np.median(nsub_arr_counter))\n",
    "                    nsub_std = np.append(nsub_std, np.std(nsub_arr_counter))\n",
    "                    nsub_max = np.append(nsub_max, np.max(nsub_arr_counter))\n",
    "                    nsub_min = np.append(nsub_min, np.min(nsub_arr_counter))\n",
    "                    nsub_skew = np.append(nsub_skew, skew(nsub_arr_counter))\n",
    "                    nsub_krt = np.append(nsub_krt, kurtosis(nsub_arr_counter))\n",
    "\n",
    "                    ratio_mean = np.append(ratio_mean, np.mean(nfoci_arr_counter / nsub_arr_counter))\n",
    "                    ratio_std = np.append(ratio_std, np.std(nfoci_arr_counter / nsub_arr_counter))\n",
    "                    ratio_max = np.append(ratio_max, np.max(nfoci_arr_counter / nsub_arr_counter))\n",
    "                    ratio_min = np.append(ratio_min, np.min(nfoci_arr_counter / nsub_arr_counter))\n",
    "                    \n",
    "                    nstudies_foci_ratio = np.append(nstudies_foci_ratio, np.sum(nfoci_arr_counter) / nstudies)\n",
    "                    \n",
    "\n",
    "                    hi_foci_counter = 0\n",
    "                    mi_foci_counter = 0\n",
    "                    li_foci_counter = 0\n",
    "                    Vi_foci_counter = 0\n",
    "                    \n",
    "                    for i in range(nstudies):\n",
    "                        if nsub_arr_counter[i] > 20:\n",
    "                            hi_foci_counter += nfoci_arr_counter[i]\n",
    "                        if (nsub_arr_counter[i] < 20) and (nsub_arr_counter[i] > 15):\n",
    "                            mi_foci_counter += nfoci_arr_counter[i]\n",
    "                        if (nsub_arr_counter[i] < 15) and (nsub_arr_counter[i] > 10):\n",
    "                            li_foci_counter += nfoci_arr_counter[i]\n",
    "                        if nsub_arr_counter[i] < 10:\n",
    "                            vi_foci_counter += nfoci_arr_counter[i]\n",
    "\n",
    "                    hi_foci = np.append(hi_foci, hi_foci_counter)\n",
    "                    mi_foci = np.append(mi_foci, mi_foci_counter)\n",
    "                    li_foci = np.append(li_foci, li_foci_counter)\n",
    "                    vi_foci = np.append(vi_foci, vi_foci_counter)\n",
    "\n",
    "print(nstudies_arr.shape)\n",
    "\n",
    "with h5py.File('input/simulation_data_cutoff_uniform.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,100):\n",
    "        for rep in range(100):\n",
    "            nstudies_arr = np.append(nstudies_arr, nstudies)\n",
    "\n",
    "            nfoci_arr_counter = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            nfoci_total = np.append(nfoci_total, np.sum(nfoci_arr_counter))\n",
    "            nfoci_mean = np.append(nfoci_mean, np.mean(nfoci_arr_counter))\n",
    "            nfoci_median = np.append(nfoci_median, np.median(nfoci_arr_counter))\n",
    "            nfoci_std = np.append(nfoci_std, np.std(nfoci_arr_counter))\n",
    "            nfoci_max = np.append(nfoci_max, np.max(nfoci_arr_counter))\n",
    "            nfoci_min = np.append(nfoci_min, np.min(nfoci_arr_counter))\n",
    "            nfoci_skew = np.append(nfoci_skew, skew(nfoci_arr_counter))\n",
    "            nfoci_krt = np.append(nfoci_krt, kurtosis(nfoci_arr_counter))\n",
    "\n",
    "            nsub_arr_counter = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            nsub_total = np.append(nsub_total, np.sum(nsub_arr_counter))\n",
    "            nsub_mean = np.append(nsub_mean, np.mean(nsub_arr_counter))\n",
    "            nsub_median = np.append(nsub_median, np.median(nsub_arr_counter))\n",
    "            nsub_std = np.append(nsub_std, np.std(nsub_arr_counter))\n",
    "            nsub_max = np.append(nsub_max, np.max(nsub_arr_counter))\n",
    "            nsub_min = np.append(nsub_min, np.min(nsub_arr_counter))\n",
    "            nsub_skew = np.append(nsub_skew, skew(nsub_arr_counter))\n",
    "            nsub_krt = np.append(nsub_krt, kurtosis(nsub_arr_counter))\n",
    "\n",
    "            ratio_mean = np.append(ratio_mean, np.mean(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_std = np.append(ratio_std, np.std(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_max = np.append(ratio_max, np.max(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_min = np.append(ratio_min, np.min(nfoci_arr_counter / nsub_arr_counter))\n",
    "\n",
    "            nstudies_foci_ratio = np.append(nstudies_foci_ratio, np.sum(nfoci_arr_counter) / nstudies)\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            Vi_foci_counter = 0\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub_arr_counter[i] > 20:\n",
    "                    hi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 20) and (nsub_arr_counter[i] > 15):\n",
    "                    mi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 15) and (nsub_arr_counter[i] > 10):\n",
    "                    li_foci_counter += nfoci_arr_counter[i]\n",
    "                if nsub_arr_counter[i] < 10:\n",
    "                    vi_foci_counter += nfoci_arr_counter[i]\n",
    "\n",
    "            hi_foci = np.append(hi_foci, hi_foci_counter)\n",
    "            mi_foci = np.append(mi_foci, mi_foci_counter)\n",
    "            li_foci = np.append(li_foci, li_foci_counter)\n",
    "            vi_foci = np.append(vi_foci, vi_foci_counter)\n",
    "\n",
    "print(nstudies_arr.shape)            \n",
    "\n",
    "with h5py.File('input/simulation_data_cutoff_highfoci.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,150):\n",
    "        for rep in range(10):\n",
    "            nstudies_arr = np.append(nstudies_arr, nstudies)\n",
    "\n",
    "            nfoci_arr_counter = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            nfoci_total = np.append(nfoci_total, np.sum(nfoci_arr_counter))\n",
    "            nfoci_mean = np.append(nfoci_mean, np.mean(nfoci_arr_counter))\n",
    "            nfoci_median = np.append(nfoci_median, np.median(nfoci_arr_counter))\n",
    "            nfoci_std = np.append(nfoci_std, np.std(nfoci_arr_counter))\n",
    "            nfoci_max = np.append(nfoci_max, np.max(nfoci_arr_counter))\n",
    "            nfoci_min = np.append(nfoci_min, np.min(nfoci_arr_counter))\n",
    "            nfoci_skew = np.append(nfoci_skew, skew(nfoci_arr_counter))\n",
    "            nfoci_krt = np.append(nfoci_krt, kurtosis(nfoci_arr_counter))\n",
    "\n",
    "            nsub_arr_counter = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            nsub_total = np.append(nsub_total, np.sum(nsub_arr_counter))\n",
    "            nsub_mean = np.append(nsub_mean, np.mean(nsub_arr_counter))\n",
    "            nsub_median = np.append(nsub_median, np.median(nsub_arr_counter))\n",
    "            nsub_std = np.append(nsub_std, np.std(nsub_arr_counter))\n",
    "            nsub_max = np.append(nsub_max, np.max(nsub_arr_counter))\n",
    "            nsub_min = np.append(nsub_min, np.min(nsub_arr_counter))\n",
    "            nsub_skew = np.append(nsub_skew, skew(nsub_arr_counter))\n",
    "            nsub_krt = np.append(nsub_krt, kurtosis(nsub_arr_counter))\n",
    "\n",
    "            ratio_mean = np.append(ratio_mean, np.mean(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_std = np.append(ratio_std, np.std(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_max = np.append(ratio_max, np.max(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_min = np.append(ratio_min, np.min(nfoci_arr_counter / nsub_arr_counter))\n",
    "\n",
    "            nstudies_foci_ratio = np.append(nstudies_foci_ratio, np.sum(nfoci_arr_counter) / nstudies)\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            Vi_foci_counter = 0\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub_arr_counter[i] > 20:\n",
    "                    hi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 20) and (nsub_arr_counter[i] > 15):\n",
    "                    mi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 15) and (nsub_arr_counter[i] > 10):\n",
    "                    li_foci_counter += nfoci_arr_counter[i]\n",
    "                if nsub_arr_counter[i] < 10:\n",
    "                    vi_foci_counter += nfoci_arr_counter[i]\n",
    "\n",
    "            hi_foci = np.append(hi_foci, hi_foci_counter)\n",
    "            mi_foci = np.append(mi_foci, mi_foci_counter)\n",
    "            li_foci = np.append(li_foci, li_foci_counter)\n",
    "            vi_foci = np.append(vi_foci, vi_foci_counter)\n",
    "\n",
    "\n",
    "print(nstudies_arr.shape)\n",
    "            \n",
    "with h5py.File('input/simulation_data_cutoff_highsub.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,150):\n",
    "        for rep in range(10):\n",
    "            nstudies_arr = np.append(nstudies_arr, nstudies)\n",
    "\n",
    "            nfoci_arr_counter = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            nfoci_total = np.append(nfoci_total, np.sum(nfoci_arr_counter))\n",
    "            nfoci_mean = np.append(nfoci_mean, np.mean(nfoci_arr_counter))\n",
    "            nfoci_median = np.append(nfoci_median, np.median(nfoci_arr_counter))\n",
    "            nfoci_std = np.append(nfoci_std, np.std(nfoci_arr_counter))\n",
    "            nfoci_max = np.append(nfoci_max, np.max(nfoci_arr_counter))\n",
    "            nfoci_min = np.append(nfoci_min, np.min(nfoci_arr_counter))\n",
    "            nfoci_skew = np.append(nfoci_skew, skew(nfoci_arr_counter))\n",
    "            nfoci_krt = np.append(nfoci_krt, kurtosis(nfoci_arr_counter))\n",
    "\n",
    "            nsub_arr_counter = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            nsub_total = np.append(nsub_total, np.sum(nsub_arr_counter))\n",
    "            nsub_mean = np.append(nsub_mean, np.mean(nsub_arr_counter))\n",
    "            nsub_median = np.append(nsub_median, np.median(nsub_arr_counter))\n",
    "            nsub_std = np.append(nsub_std, np.std(nsub_arr_counter))\n",
    "            nsub_max = np.append(nsub_max, np.max(nsub_arr_counter))\n",
    "            nsub_min = np.append(nsub_min, np.min(nsub_arr_counter))\n",
    "            nsub_skew = np.append(nsub_skew, skew(nsub_arr_counter))\n",
    "            nsub_krt = np.append(nsub_krt, kurtosis(nsub_arr_counter))\n",
    "\n",
    "            ratio_mean = np.append(ratio_mean, np.mean(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_std = np.append(ratio_std, np.std(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_max = np.append(ratio_max, np.max(nfoci_arr_counter / nsub_arr_counter))\n",
    "            ratio_min = np.append(ratio_min, np.min(nfoci_arr_counter / nsub_arr_counter))\n",
    "\n",
    "            nstudies_foci_ratio = np.append(nstudies_foci_ratio, np.sum(nfoci_arr_counter) / nstudies)\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            Vi_foci_counter = 0\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub_arr_counter[i] > 20:\n",
    "                    hi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 20) and (nsub_arr_counter[i] > 15):\n",
    "                    mi_foci_counter += nfoci_arr_counter[i]\n",
    "                if (nsub_arr_counter[i] < 15) and (nsub_arr_counter[i] > 10):\n",
    "                    li_foci_counter += nfoci_arr_counter[i]\n",
    "                if nsub_arr_counter[i] < 10:\n",
    "                    vi_foci_counter += nfoci_arr_counter[i]\n",
    "\n",
    "            hi_foci = np.append(hi_foci, hi_foci_counter)\n",
    "            mi_foci = np.append(mi_foci, mi_foci_counter)\n",
    "            li_foci = np.append(li_foci, li_foci_counter)\n",
    "            vi_foci = np.append(vi_foci, vi_foci_counter)\n",
    "\n",
    "print(nstudies_arr.shape)\n",
    "            \n",
    "            \n",
    "X_full = np.c_[nstudies_arr,\n",
    "               nsub_total, nsub_mean, nsub_median, nsub_std, nsub_max, nsub_min, nsub_skew, nsub_krt,\n",
    "               nfoci_total, nfoci_mean, nfoci_median, nfoci_std, nfoci_max, nfoci_min, nfoci_skew, nfoci_krt,\n",
    "               ratio_mean, ratio_std, ratio_max, ratio_min, nstudies_foci_ratio,\n",
    "               hi_foci, mi_foci, li_foci, vi_foci]\n",
    "\n",
    "ale_cutoffs = np.empty((0))\n",
    "cluster_cutoffs = np.empty((0))\n",
    "for counter, nstudies in enumerate(range(10,150)):\n",
    "    with h5py.File(f'input/nulls/{nstudies}_null.hdf5', 'r') as f:\n",
    "        ale_cutoffs = np.hstack((ale_cutoffs, f['ale'][:]))\n",
    "        cluster_cutoffs = np.hstack((cluster_cutoffs, f['cluster'][:]))\n",
    "\n",
    "with h5py.File(f'input/extremes_null.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,150):\n",
    "        for foci_cat in ['low','medium','high']:\n",
    "            for subj_cat in ['low','medium','high']:\n",
    "                ale_cutoffs = np.append(ale_cutoffs, f[f'{nstudies}/{foci_cat}/{subj_cat}/ale'][:])\n",
    "                cluster_cutoffs = np.append(cluster_cutoffs, f[f'{nstudies}/{foci_cat}/{subj_cat}/cluster'][:])\n",
    "                \n",
    "with h5py.File(f'input/uniform_null.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,100):\n",
    "        ale_cutoffs = np.append(ale_cutoffs, f[f'{nstudies}/ale'][:])\n",
    "        cluster_cutoffs = np.append(cluster_cutoffs, f[f'{nstudies}/cluster'][:])\n",
    "        \n",
    "with h5py.File(f'input/highfoci_null.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,150):\n",
    "        ale_cutoffs = np.append(ale_cutoffs, f[f'{nstudies}/ale'][:])\n",
    "        cluster_cutoffs = np.append(cluster_cutoffs, f[f'{nstudies}/cluster'][:])\n",
    "\n",
    "\n",
    "with h5py.File(f'input/highsub_null.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,150):\n",
    "        ale_cutoffs = np.append(ale_cutoffs, f[f'{nstudies}/ale'][:])\n",
    "        cluster_cutoffs = np.append(cluster_cutoffs, f[f'{nstudies}/cluster'][:])\n",
    "\n",
    "\n",
    "X_shfl, ac_shfl, cc_shfl, order = unison_shuffled_copies(X_full, ale_cutoffs, cluster_cutoffs)\n",
    "\n",
    "np.savez('output/X_shfl.npz', data=X_shfl)\n",
    "np.savez('output/ac_shfl.npz', data=ac_shfl)\n",
    "np.savez('output/cc_shfl.npz', data=cc_shfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b462d34-8405-4adf-b79a-64575d1c31e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.zeros((24400,26))\n",
    "counter = 0\n",
    "\n",
    "with h5py.File('input/simulation_data_cutoff_normal.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,150):\n",
    "        \n",
    "        for rep in range(100):\n",
    "            x[counter,0] = nstudies\n",
    "\n",
    "            nsub = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            x[counter,1] = np.sum(nsub)\n",
    "            x[counter,2] = np.mean(nsub)\n",
    "            x[counter,3] = np.median(nsub)\n",
    "            x[counter,4] = np.std(nsub)\n",
    "            x[counter,5] = np.max(nsub)\n",
    "            x[counter,6] = np.min(nsub)\n",
    "            x[counter,7] = skew(nfoci)\n",
    "            x[counter,8] = kurtosis(nfoci)\n",
    "            \n",
    "            nfoci = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            x[counter,9] = np.sum(nfoci)\n",
    "            x[counter,10] = np.mean(nfoci)\n",
    "            x[counter,11] = np.median(nfoci)\n",
    "            x[counter,12] = np.std(nfoci)\n",
    "            x[counter,13] = np.max(nfoci)\n",
    "            x[counter,14] = np.min(nfoci)\n",
    "            x[counter,15] = skew(nfoci)\n",
    "            x[counter,16] = kurtosis(nfoci)\n",
    "\n",
    "            x[counter,17]= np.mean(nfoci / nsub)\n",
    "            x[counter,18] = np.std(nfoci / nsub)\n",
    "            x[counter,19] = np.max(nfoci / nsub)\n",
    "            x[counter,20] = np.min(nfoci / nsub)\n",
    "\n",
    "            x[counter,17] = np.sum(nfoci) / nstudies\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            vi_foci_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub[i] > 20:\n",
    "                    hi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 20) and (nsub[i] > 15):\n",
    "                    mi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 15) and (nsub[i] > 10):\n",
    "                    li_foci_counter += nfoci[i]\n",
    "                if nsub[i] < 10:\n",
    "                    vi_foci_counter += nfoci[i]\n",
    "\n",
    "            x[counter,21] = hi_foci_counter\n",
    "            x[counter,22] = mi_foci_counter\n",
    "            x[counter,23] = li_foci_counter\n",
    "            x[counter,24] = vi_foci_counter\n",
    "\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            \n",
    "with h5py.File('input/simulation_data_cutoff_uniform.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,100):\n",
    "        for rep in range(100):\n",
    "            x[counter,0] = nstudies\n",
    "\n",
    "            nsub = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            x[counter,1] = np.sum(nsub)\n",
    "            x[counter,2] = np.mean(nsub)\n",
    "            x[counter,3] = np.median(nsub)\n",
    "            x[counter,4] = np.std(nsub)\n",
    "            x[counter,5] = np.max(nsub)\n",
    "            x[counter,6] = np.min(nsub)\n",
    "            x[counter,7] = skew(nfoci)\n",
    "            x[counter,8] = kurtosis(nfoci)\n",
    "            \n",
    "            nfoci = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            x[counter,9] = np.sum(nfoci)\n",
    "            x[counter,10] = np.mean(nfoci)\n",
    "            x[counter,11] = np.median(nfoci)\n",
    "            x[counter,12] = np.std(nfoci)\n",
    "            x[counter,13] = np.max(nfoci)\n",
    "            x[counter,14] = np.min(nfoci)\n",
    "            x[counter,15] = skew(nfoci)\n",
    "            x[counter,16] = kurtosis(nfoci)\n",
    "\n",
    "            x[counter,17]= np.mean(nfoci / nsub)\n",
    "            x[counter,18] = np.std(nfoci / nsub)\n",
    "            x[counter,19] = np.max(nfoci / nsub)\n",
    "            x[counter,20] = np.min(nfoci / nsub)\n",
    "\n",
    "            x[counter,17] = np.sum(nfoci) / nstudies\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            vi_foci_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub[i] > 20:\n",
    "                    hi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 20) and (nsub[i] > 15):\n",
    "                    mi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 15) and (nsub[i] > 10):\n",
    "                    li_foci_counter += nfoci[i]\n",
    "                if nsub[i] < 10:\n",
    "                    vi_foci_counter += nfoci[i]\n",
    "\n",
    "            x[counter,21] = hi_foci_counter\n",
    "            x[counter,22] = mi_foci_counter\n",
    "            x[counter,23] = li_foci_counter\n",
    "            x[counter,24] = vi_foci_counter\n",
    "\n",
    "\n",
    "            counter += 1\n",
    "            \n",
    "\n",
    "            \n",
    "with h5py.File('input/simulation_data_cutoff_highfoci.hdf5','r') as sim_data:\n",
    "    for nstudies in range(10,150):\n",
    "        for rep in range(10):\n",
    "            x[counter,0] = nstudies\n",
    "\n",
    "            nsub = sim_data[f'{nstudies}/{rep}/nsub'][:]\n",
    "            x[counter,1] = np.sum(nsub)\n",
    "            x[counter,2] = np.mean(nsub)\n",
    "            x[counter,3] = np.median(nsub)\n",
    "            x[counter,4] = np.std(nsub)\n",
    "            x[counter,5] = np.max(nsub)\n",
    "            x[counter,6] = np.min(nsub)\n",
    "            x[counter,7] = skew(nfoci)\n",
    "            x[counter,8] = kurtosis(nfoci)\n",
    "            \n",
    "            nfoci = sim_data[f'{nstudies}/{rep}/nfoci'][:]\n",
    "            x[counter,9] = np.sum(nfoci)\n",
    "            x[counter,10] = np.mean(nfoci)\n",
    "            x[counter,11] = np.median(nfoci)\n",
    "            x[counter,12] = np.std(nfoci)\n",
    "            x[counter,13] = np.max(nfoci)\n",
    "            x[counter,14] = np.min(nfoci)\n",
    "            x[counter,15] = skew(nfoci)\n",
    "            x[counter,16] = kurtosis(nfoci)\n",
    "\n",
    "            x[counter,17]= np.mean(nfoci / nsub)\n",
    "            x[counter,18] = np.std(nfoci / nsub)\n",
    "            x[counter,19] = np.max(nfoci / nsub)\n",
    "            x[counter,20] = np.min(nfoci / nsub)\n",
    "\n",
    "            x[counter,21] = np.sum(nfoci) / nstudies\n",
    "\n",
    "            hi_foci_counter = 0\n",
    "            mi_foci_counter = 0\n",
    "            li_foci_counter = 0\n",
    "            vi_foci_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(nstudies):\n",
    "                if nsub[i] > 20:\n",
    "                    hi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 20) and (nsub[i] > 15):\n",
    "                    mi_foci_counter += nfoci[i]\n",
    "                if (nsub[i] < 15) and (nsub[i] > 10):\n",
    "                    li_foci_counter += nfoci[i]\n",
    "                if nsub[i] < 10:\n",
    "                    vi_foci_counter += nfoci[i]\n",
    "\n",
    "            x[counter,22] = hi_foci_counter\n",
    "            x[counter,23] = mi_foci_counter\n",
    "            x[counter,24] = li_foci_counter\n",
    "            x[counter,25] = vi_foci_counter\n",
    "\n",
    "            counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4288aa-58bc-4857-a9bb-d877b49de334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('output/X_tfce_shfl', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a95b055-d4fd-402b-9ae3-13beee627be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfce_cutoffs = np.empty((0))\n",
    "\n",
    "with h5py.File(f'input/tfce_nulls_normal.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,150):\n",
    "        tfce_cutoffs = np.append(tfce_cutoffs, f[f'{nstudies}'][:])\n",
    "\n",
    "with h5py.File(f'input/tfce_nulls_uniform.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,100):\n",
    "        tfce_cutoffs = np.append(tfce_cutoffs, f[f'{nstudies}'][:])\n",
    "            \n",
    "with h5py.File(f'input/tfce_nulls_highfoci.hdf5', 'r') as f:\n",
    "    for nstudies in range(10,150):\n",
    "        tfce_cutoffs = np.append(tfce_cutoffs, f[f'{nstudies}'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a348494-490c-4e3c-adc0-015e2dbbadd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('output/tfce_cutoff_shfl', tfce_cutoffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyALE",
   "language": "python",
   "name": "pyale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
